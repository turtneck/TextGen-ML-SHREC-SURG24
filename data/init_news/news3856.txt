Yesterday Facebook released a study in Science that pushed back on the idea of the filter bubble that social media creates a kind of echo chamber in which users never see arguments from the other side helping to insulate those usersfrom substantive political debateTaken to its extreme the Filter Bubble might almost completely close users off to new ideas and information leaving them in a digital world where their viewpoints go ever unchallengedand contributing to politicalpolarizationFacebook Use Polarizing Site Begs to Differthe New YorkTimesheadline readYou would think that if there was an echo chamber you would not be exposed to any conflicting information a data scientist who worked onthe study said but thats not the casehereBut looking at the study I came to very different conclusions It absolutely shows that the filter bubble exists among some users and that Facebook and its algorithms play a significant role in creating that bubble But I can only make that claim about a small number of users that are likely not at all representative of the broader Facebook population because Facebook relied on such an unusual sample of its usersIn other words despite the buzz this study is gettingwe still dont have a very good sense of howFacebook and other socialmedia servicesmight or might not contribute topolarizationAspointed outby Nathan Jurgenson the study only looks at people who selfidentify their political orientation on the site That means it only examines 9 percent of users a number youd only see if you read through the appendix he notes It also only looks at Facebook users who log in four to seven days a week and who meet a few other criteria as well That nudges the proportion of users examined in the study down to just 4 percent or about 10 millionusersAre those 4 percent of users representative of Facebooks user base as a whole Well they arent randomly sampled We know that identifying your political affiliation is a fairly rare behavior given that fewer than one in ten users bothers to do so My guess is that those users are much more politically engaged and likely much more partisan than the average user and thats probably going to affect what they click on and whom they are friends with But how and how much that matters I cannotsayThere could also be something different about those Facebook users who log in frequently maybe they post more or leave more comments Again we dont know But the point is that if you want to make any broad conclusions about a big population based on a study you need a random representative sample You cant survey three rich guys in Greenwich and declare that Americas favorite food iscaviarSocialmedia experts and data scientists are taking Facebook to task for not making all this clearer At first I read this quickly and I took this to mean that out of the at least 200 million Americans who have used Facebook the researchers selected a large sample that was representative of Facebook userswritesChristian Sandvig of the University of Michigan The limitations section discusses the demographics of Facebooks users as would be the normal thing to do if they were sampled There is no information about the selection procedure in the articleitselfBut even setting aside the sample issues the study clearly does not show that those unusual users are exposed to a diverse set of viewpoints nudged along by the Facebook algorithmIt shows that they see a fairly skewed set of viewpoints with the Facebook algorithmcontributing to the skewFacebook filters out about 1 in 20 crosscutting hardnews stories for conservatives and about 1 in 13 crosscutting hardnews stories forliberalsFacebook attempts to distance itself from filterbubble accusations by noting that individuals isolate themselves too with selfidentified conservatives clicking on 17 percent fewer crosscutting news stories than would be expected if they clicked at random and liberals 6 percent fewer The company used that finding to argue that it plays less of a role than individuals themselves But thats only true for conservatives  not forliberalsAnd its not clear that Facebook can or should be arguing that it plays a smaller filtering role than individuals given how the study was conducted in the first place and given that the two findings do not seem directly comparable I cannot remember a worse apples to oranges comparison Ive seen recently especially since these two dynamics algorithmic suppression and individual choice have cumulative effectswritesZeynep Tufekci of the University of NorthCarolinaNo the filter bubble feels like a very real phenomenon and Facebook has just shown that for some users it contributes to it On social media we hear what we want to hear see what we want to see and click what we want to click Dont let Facebook tell youotherwise