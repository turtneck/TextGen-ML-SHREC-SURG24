Critics have worried that thealgorithm Facebook uses to determine what users see could be creating bubbles that allow us to see only what we agree with A new study finds that users are driving the trend more than Facebook itselfFacebook users do more to seal themselves within their own political news and opinion bubbles than the social media sites algorithms do according to a study published Thursday in the journal Science ExpressA quick Google search for the socialmedia giant Facebook turns up a range of provocative questions Is Facebook making us lonely Is Facebook losing its cool Is Facebook dyingScientists at Facebook have added another Is Facebook reinforcing ideological bubbles that users build around themselvesTheir short answer is yes But the effect is small compared with contributions users themselves make Users build those bubbles through their choice of friends what those friends share and the extent to which users open links to news or opinion material that would offer views that run counter to the users viewOn one level the results published Thursday in the online journal Science Express suggest that for now social media and their complex userfocused algorithms arent to blame for the nations growing political polarizationThat polarization is a trend many political and information scientists see as a threat to a welloiled democracy which relies on people with competing ideologies working together toward shared goals The study reinforces the observation that people are bringing to the virtual world their realworld tendencies to surround themselves with people who think like they doOn another level however the small internal effect the researchers detected from Facebooks algorithm should raise warning flags says David Lazer a political scientist at Northeastern University who focuses in part on the impact of the internet on politics and was not a member of the study teamTheres nothing in the algorithm that says Lets polarize America he says But the simple rules that might make content more engaging may also result in this kind of bubbleHe notes that Facebook recently tweaked it algorithm in part to make sure a user sees more material from people a user identifies as close friendsClose friends are probably more similar to you in many ways than your distant acquaintances So its quite plausible that the change will have the unintended consequence of further narrowing the range of perspectives that enter a users news feed he saysThe new study grew out of surprising results in previous work which looked at how users got their information on Facebook says Eytan Bakshy a data scientist at Facebook and the studys lead author The earlier study found that on average the less frequently you interact with a Facebook friend the more likely you are to share items that come from that friendTo our surprise we found that the majority of information that you click on and you end up resharing comes from weaker ties people with whom you interact relatively rarely Dr Bakshy says These people have the potential to be more dissimilar to youThat raised a question What does this imply for the notion of social media as an echo chamber in which people surround themselves only with people who think like they doOthers have tried to tackle that question with conflicting results  often in no small part because the sample sizes in the study groups were relatively smallBakshy and colleagues tapped data and activity for some 101 million Facebook users in the United States using protocols that ensured their anonymity These people had listed a political affiliation in their profiles In addition the team focused on shared content they dubbed hard news or opinion  politics US news in general and international news No cats or childrens birthday parties Ideology of the source was based on the organization tied to a web link rather than the content of specific articlesWhen the researchers parsed the data they found that on average 23 percent of a users friends are people whose politics are from the other side Despite the heavy tilt in friends toward like me just under 30 percent of the incoming news represented the other sides perspective  socalled crosscutting materialOverall the algorithm organizing what a user is most likely to see reduces crosscutting content by slightly less than 1 percent while a users selfbuilt bubble reduces that content by about 4 percentGiven the relatively small influence of the algorithm the results are not all that different from a lot of what we know about how people are acting across ideological and party lines in the real world says Patrick Miller a political scientist at the University of Kansas at Lawrence who also studies the interplay between social media and politicsIn many ways a dont shoot me Im just the piano player sensibility about the study is justified he suggests A vast amount of socialscience research has made it very clear that when people are building their online social networks theyre building them to reflect their offline social networksAnd offline people live in partisan bubbles in a country that has become increasingly polarized he addsBut that doesnt let Facebook off the hook as the algorithms designer others cautionSelectivity has always existed But now were living in different world says Dietram Scheufele who specializes in science communication at the University of Wisconsin at Madison Facebook is enabling levels of selectivity that have never been possible beforeFor instance he says research has shown that two people with identical friends will get different news feeds from each other based on the pictures the two clicked on posts from those friends they liked or even something as unrelated to friends as the websitesthey used Facebook to log intoAlthough people always have built ideological bubbles that doesnt mean we have to make it worse online he saysYet its also true that people would be overwhelmed by posts if some sort of sifting wasnt done ahead of time Northeasterns Professor Lazer acknowledgesPerhaps the studys biggest contribution is to provoke a recognition about how much information being gathered about people is being archived and used for everything from organizing and presenting Facebook news items to setting different prices on items sold on ecommerce sites based on information gathered about the purchaserA lot of the algorithms that focus choices based on personal profiles are done for our convenience but some of it frankly is to exploit us he saysIm not saying we need to go back to the preinternet age he says But in Matrix like fashion the line between the real and virtual worlds are blurring he addsWe have to think about what is good and what is bad This study doesnt answer that question but it does provoke the question Were really behind where we should be in terms of debating these things as a society he says